{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install stable-baselines3[extra] protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install mss pydirectinput pytesseract gym tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chrome://dino/\n",
    "#edge://surf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mss import mss\n",
    "import pydirectinput\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import gymnasium \n",
    "from gymnasium  import Env\n",
    "from gymnasium .spaces import Box, Discrete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Build the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Create Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WebGame(gymnasium .Env):\n",
    "\n",
    "    # Setup the environment and observation shapes\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # Setup spaces\n",
    "        self.observation_space = Box(low=0, high=255, shape=(1,83,100), dtype=np.uint8)\n",
    "        self.action_space = Discrete(3)\n",
    "        # Capture game frames\n",
    "        self.cap = mss()\n",
    "        self.game_location = {'top': 250, 'left': 0, 'width': 650, 'height': 500}\n",
    "        self.done_location = {'top': 350, 'left': 630, 'width': 660, 'height': 70}\n",
    "        \n",
    "    # Setup Game control\n",
    "    def step(self, action):\n",
    "        action_map = {\n",
    "            0: 'space',\n",
    "            1: 'no_op'\n",
    "        }\n",
    "        if action == 0:\n",
    "            pydirectinput.press(action_map[action])\n",
    "\n",
    "        done, done_cap = self.get_done() \n",
    "        observation = self.get_observation()\n",
    "        reward = 1 \n",
    "        terminated = done\n",
    "        truncated = False  # Set this based on your environment's logic if needed\n",
    "        info = {}\n",
    "        return observation, reward, terminated, truncated, info  # Returning five values\n",
    "        \n",
    "    # Restart game \n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "        time.sleep(1)\n",
    "        pydirectinput.click(x=150, y=150)\n",
    "        pydirectinput.press('space')\n",
    "        observation = self.get_observation()\n",
    "        info = {}\n",
    "        return observation, info\n",
    "    \n",
    "    # Visualize the game    \n",
    "    def render(self):\n",
    "        cv2.imshow('Game', self.current_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            self.close()\n",
    "    \n",
    "    # Close the observation\n",
    "    def close(self):\n",
    "        cv2.destroyAllWindows()\n",
    "    \n",
    "    # Get the observation of specific part of the game\n",
    "    def get_observation(self):\n",
    "        raw = np.array(self.cap.grab(self.game_location))[:,:,:3].astype(np.uint8)\n",
    "        gray = cv2.cvtColor(raw, cv2.COLOR_BGR2GRAY)\n",
    "        resized = cv2.resize(gray, (100,83))\n",
    "        channel = np.reshape(resized, (1,83,100))\n",
    "        return channel\n",
    "    \n",
    "    # Get the done text\n",
    "    def get_done(self):\n",
    "        done_cap = np.array(self.cap.grab(self.done_location))\n",
    "        done_strings = ['GAME', 'GAHE']\n",
    "        done=False\n",
    "        # if np.sum(done_cap) < 44300000:\n",
    "        #     done = True\n",
    "        done = False\n",
    "        res = pytesseract.image_to_string(done_cap)[:4]\n",
    "        if res in done_strings:\n",
    "            done = True\n",
    "        return done, done_cap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.get_observation().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "obs=env.get_observation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(obs[0], cv2.COLOR_GRAY2BGR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done, done_cap = env.get_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(done_cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.image_to_string(done_cap)[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for episode in range(10): \n",
    "    obs = env.reset()\n",
    "    done = False  \n",
    "    total_reward   = 0\n",
    "    while not done: \n",
    "        obs, reward,  done, info =  env.step(env.action_space.sample())\n",
    "        total_reward  += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Create Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import os for file path management\n",
    "import os \n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "# Check Environment    \n",
    "from stable_baselines3.common import env_checker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = './train/'\n",
    "LOG_DIR = './logs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = TrainAndLoggingCallback(check_freq=1000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Build DQN and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecFrameStack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = WebGame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = DQN('CnnPolicy', env, tensorboard_log=LOG_DIR, verbose=1, buffer_size=420000, learning_starts=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=100000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load('train/best_model_66000') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test out Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for episode in range(5): \n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    while not done: \n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(int(action))\n",
    "        time.sleep(0.01)\n",
    "        total_reward += reward\n",
    "    print('Total Reward for episode {} is {}'.format(episode, total_reward))\n",
    "    time.sleep(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "webgame-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
